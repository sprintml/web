---
layout: post
title:  "87 days to go: How to navigate the paper jungle?"
date:   2023-06-07 
tags: phd life, related work, papers
---

*by Franziska Boenisch and Adam Dziedzic*

We all know, there are many papers out there and it is hard to find the right ones. We have some tips and tricks on how you can find good papers on your new research topic.
Note that the following insights are probably a bit tailored to our field, namely machine learning, but we hope that Ph.D. students from other fields can also get something out of it.

Forward and backward search on Google Scholar or arXiv: In the best case, you have some initial pointers for papers from your advisor. If you want to move on from there, all you’ll need to do is to look at *citations*. They can help you identify both research that is in the past of the papers to provide you with a more thorough background, and research that is in the future of the paper, leading you towards the newest developments (for example, check arXiv -> Bibliographic Tools ->  Bibliographic Explorer). You’ll find the past work by looking at the citations at the bottom of your current paper. By looking the referenced titles up on [Google Scholar](https://scholar.google.com), you can easily identify relevant background and read more to deepen your understanding. When it comes to finding work that was done based on the paper you are currently looking at, you can search for the title on Google Scholar and click on the “cited by” button. This will lead you to a list of all papers that have cited (and thereby potentially built on) your current paper.

If you do so, you should try to avoid *citation bubbles* though. Some researchers that follow the same line of thought or are linked by institutions or personal links have tendencies to cite each other more than external related work. So in addition to searching based on the papers you have, we recommend you to also do a keyword search, for example on Google Scholar or [Research Gate](https://www.researchgate.net), just to be sure that you are not missing anything relevant.

Finally, note that in addition to the hundreds to thousands of accepted papers at machine learning conferences every year, nowadays there are also hundreds of new papers submitted to preprint servers, such as [arXiv](https://arxiv.org) every week. This makes the task of finding papers that you can trust much more difficult. We’ll talk about how to identify trustworthy papers tomorrow.

